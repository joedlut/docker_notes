namespace + cgroups

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice# ls | grep docker
docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope
docker.service
docker.socket
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice# docker ps
CONTAINER ID   IMAGE                 COMMAND           CREATED       STATUS       PORTS     NAMES
3ec18d539ddd   centos/httpd:latest   "/run-httpd.sh"   4 hours ago   Up 4 hours   80/tcp    inspiring_cray

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cgroup.procs 
5843
5875
5876
5877
5878
5879
5880
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cgroup.procs 
5843
5875
5876
5877
5878
5879
5880
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls 
cgroup.controllers      cgroup.threads         cpuset.mems            hugetlb.1GB.events.local  hugetlb.2MB.numa_stat     memory.events        memory.pressure       misc.current
cgroup.events           cgroup.type            cpuset.mems.effective  hugetlb.1GB.max           hugetlb.2MB.rsvd.current  memory.events.local  memory.reclaim        misc.events
cgroup.freeze           cpu.idle               cpu.stat               hugetlb.1GB.numa_stat     hugetlb.2MB.rsvd.max      memory.high          memory.stat           misc.max
cgroup.kill             cpu.max                cpu.uclamp.max         hugetlb.1GB.rsvd.current  io.max                    memory.low           memory.swap.current   pids.current
cgroup.max.depth        cpu.max.burst          cpu.uclamp.min         hugetlb.1GB.rsvd.max      io.pressure               memory.max           memory.swap.events    pids.events
cgroup.max.descendants  cpu.pressure           cpu.weight             hugetlb.2MB.current       io.prio.class             memory.min           memory.swap.high      pids.max
cgroup.procs            cpuset.cpus            cpu.weight.nice        hugetlb.2MB.events        io.stat                   memory.numa_stat     memory.swap.max       rdma.current
cgroup.stat             cpuset.cpus.effective  hugetlb.1GB.current    hugetlb.2MB.events.local  io.weight                 memory.oom.group     memory.zswap.current  rdma.max
cgroup.subtree_control  cpuset.cpus.partition  hugetlb.1GB.events     hugetlb.2MB.max           memory.current            memory.peak          memory.zswap.max
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep memory.li
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep limit

kill pid SIGTERM 15 default 可以被捕获 用于处理graceful-shutdown
kill -9 pid SIGKILL 9  不可以被捕获或者忽略  特权信号

内核决定给1号进程发送信号的时候，会调用sig_task_ignored来判断是否忽略
sig_task_ignored() 收到信号后会做一个判断，决定什么情况下内核会忽略掉信号不再处理,如果下面的三个条件都满足，这个信号就不会发送给进程
  值force 同一个namespace发出的信号值一直是0  !0 满足
  信号的handler是否是SIG_DFL,是就忽略，对于每个信号，如果用户进程不自己注册一个自己的handler,就会有一个系统缺省的handler,这个缺省的handler就是SIG_DFL  SIG_KILL满足（不允许被捕获，不允许自定义handler,handler是DFL），SIG_TERM如果没有自己注册handler,也是满足的
  SIGNAL_UNKILLABLE标签 flag ，只要是一号进程，就会有这个flag,满足
  关键是第二个条件，handler == DFL linux内核针对每个namespace里的init进程，把只有default handler的信号给忽略掉了

  所以init进程永远不能被SIGKILL杀死，可以被SIGTERM杀死 

  kill -9 1在容器中不工作，内核阻止了1号进程对sigkill特权信号的响应(信号的handler是 DFL)
  kill 1 分为两种情况，如果1号进程没有注册sigterm的handler,对sigterm信号不响应(C)，如果注册了sigterm的信号的handler,那么可以响应sigterm的信号（golang）
  
  1号进程是第一个用户态进程，由它直接或者间接创建了namespace中的其他进程

  linux 31个信号量 

  进程处理信号的三个情况：
  忽略 SIGKILL SIGSTOP除外
  捕获 进程注册自己的handler 捕获信号自己处理,而不会执行缺省代码
  缺省 

  进程或者线程 task_struct{}结构体

  linux机器允许创建的最大进程数目 
  /proc/sys/kernel/pid_max中

  限制容器中允许创建的最大进程数目  /sys/fs/cgroup/pids

 容器中允许被创建的最大进程数 
 [root@3ec18d539ddd cgroup]# cat /sys/fs/cgroup/pids.max 
2232

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep pids.max 
pids.max
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat pids.max 
2232
echo 1002 > pids.max

残留的僵尸进程依然占据着进程号资源，很有可能导致新的进程不能流转

如何处理僵尸进程？
僵尸进程产生的原因： 父进程创建之后就不再负责
解决： 父进程调用wait()系统调用，回收僵尸进程最后的资源，进程号

wait()是 阻塞的系统调用，没有子进程是僵尸进程的话，就会阻塞住
改用waitpid() 使用WHOHANG的参数，没有僵尸进程就会立即返回。
---------------------------------------------------------------
退出清理的操作，一般都是在SIGTERM信号用户注册的handler进行

containerd停止容器的时候，会向容器的init进程发出一个SIGTERM信号，而其他进程收到的是SIGKILL信号 （因为zap_pids_ns_processes()）

两个系统调用
kill() 发送信号
signal() 进程收到信号后的行为
    1.忽略  signal(SIGTERM,SIG_IGN)
    2.捕获，自定义处理handler signal(SIGTERM,sig_handler)   void sig_handler(int signo)
    3.缺省 signal(SIGTERM,SIG_DFL)  比如SIGTERM的缺省就是 terminate

SIGKILL 跟 SIGSTOP不能被捕获和忽略  signal(SIGKILL,sig_handler)会报错

linux内核处理进程退出：
do_exit() 回收进程相关资源
exit_notify() 通知进程相关的父子进程
zap_pid_ns_processes() 如果处于退出状态的是init进程，向同一个pid namespace的其他进程发送一个SIGKILL信号 

如何解决容器的应用程序被强制杀死？
在容器中的init进程中对收到的信号做个转发，发送给容器中的其他子进程，这样容器中的所有进程停止时，都会收到SIGTERM，而不是SIGKILL


--------------------------------CPU-------------------------------------
hi si 的CPU时间不会计入进程的CPU时间，因为他们本身处理的时候，不属于任何一个进程
ni nice(1-19) 进程优先级比较低的进程运行时候占用的cpu 

cgroup cpu /sys/fs/cgroup/cpu
每个控制组都是一个子目录，各个控制组的关系就是一个树状层级关系
普通调度的算法 CFS  completely fair scheduler 完全公平调度器
1.  cpu.cfs_period_us CFS调度算法的一个调度周期，一般是100ms   100 000   固定值
2.  cpu.cfs_quota_us 一个调度周期中这个控制组被允许的运行时间，比如50ms  50 000 
cpu.cfs_quota_us/cpu.cfs_period_us  = 该控制组被允许使用的cpu最大配额   50ms/100ms = 0.5 CPU 
3. cpu.shares cgroup对于控制组之间的CPU分配比例，默认是1024   group3 3072   group4 1024    group4:group3 = 3:1 

注意： cpu.shares是几个控制组之间的CPU分配比例，一定要等整个结点的cpu都跑满的之后才会发起作用

k8s cpu limits的原理
k8s 为每个容器都在 cpu cgroup的子系统中新建一个控制组，然后把容器的进程写到这个控制组中， 然后修改  cpu.cfs_quota_us设置limits 

k8s cpu requests的原理  (即 整个结点cpu被占满的情况下，容器可以获取的cpu数目)
通过设置 cpu.share参数，cpu.shares == 1024表示1个cpu的比例，request cpu的值是n, 给cpu.shares的赋值对应的是 n * 1024

cpu usage = us(或者ni) + sy 

--------------------------如何正确拿到容器CPU的开销-------------------------------
容器中运行top命令，实际看到的是容器宿主机的 cpu使用率, 原因是 /proc/stat 不包含在任一namespace中，它反应的是整个节点的cpu使用情况
对于top命令来说，它只能显示整个结点的CPU使用情况，不能显示单个容器的各项cpu的使用率

对于linux主机：
单个进程CPU使用率计算  /proc/[pid]/stat 计算用户态 跟 内核态的ticks数之和
系统CPU的使用率 /proc/stat 

如何计算整个容器的cpu使用率？
cpuacct.stat 包含了两个值，控制组内所有进程的内核态ticks 跟 用户态ticks

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cpu.stat 
usage_usec 2900606
user_usec 1440885
system_usec 1459720
nr_periods 0
nr_throttled 0
throttled_usec 0
nr_bursts 0
burst_usec 0
---------------------------------------------------------------------------
load average =  单位时间内正在运行的进程 + 可运行队列的进程 + 休眠队列中不可打断（TASK_UNINTERRUPTIBLE）的进程     

TASK_UNINTERRUPTIBLE是linux进程状态中的一种，是进程为了等待某个系统资源进入了睡眠状态，并且这个状态是不可以被信号打断的  ps ux | grep " D "   造成D状态进程的原因  主要是disk I/O 跟信号量的访问竞争，目前cgroups 还不能解决 由于D状态的进程导致容器中进程性能下降的原因。 cgrups 更多的是影响以进程为单位进行隔离，而D状态的进程是内核中系统全局资源引入的，所以cgroups影响不了它。

需要监控生产环境中D状态的进程数量，然后对D状态的进程数目异常的节点进行分析，比如磁盘故障引起的D状态进程增加

-----------------------------容器内存--------------------------------------
容器在系统中被杀掉，只有一种情况 OOM， 容器发生OOM多是因为 memory cgroup 的限制导致的

使用docker inspect container_id  查看容器退出的原因

OOM根据如何选择被杀的进程
1.进程已经使用的物理内存页面数
2. 每个进程的 OOM 校准值   /proc/[pid]/oom_score_adj (-1000 - 1000),通过调整这个文件，可以调整进程被OOM杀死的几率

内核函数 oom_badness() 判断杀死哪个进程 的计算方法：
用系统总的可用页面数 乘以 OOM校准值 再加上  进程已经使用的物理页面数，计算的数值越大，被OOM杀死的几率越大 

k8s memory limits 原理， 调整 memory cgroup 参数  memory.limit_in_bytes 

如何快速定位容器发生了OOM?
查看内核日志  journalctl -k   或者查看/var/log/message

----------------------------------------------------------------------------------
memory group不会对内核的内存做限制

用户态内存
RSS
   进程真正申请到的物理内存大小  malloc只是把内存的虚拟地址返回给了进程，进程实际对内存读写的时候，系统才会分配内存。
   RSS = 进程的代码段内存 + 栈内存 + 堆内存 + 共享库内存   查看每一部分的内存大小： /proc/[pid]/smaps
Page Cache



