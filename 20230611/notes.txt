namespace + cgroups

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice# ls | grep docker
docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope
docker.service
docker.socket
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice# docker ps
CONTAINER ID   IMAGE                 COMMAND           CREATED       STATUS       PORTS     NAMES
3ec18d539ddd   centos/httpd:latest   "/run-httpd.sh"   4 hours ago   Up 4 hours   80/tcp    inspiring_cray

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cgroup.procs 
5843
5875
5876
5877
5878
5879
5880
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cgroup.procs 
5843
5875
5876
5877
5878
5879
5880
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls 
cgroup.controllers      cgroup.threads         cpuset.mems            hugetlb.1GB.events.local  hugetlb.2MB.numa_stat     memory.events        memory.pressure       misc.current
cgroup.events           cgroup.type            cpuset.mems.effective  hugetlb.1GB.max           hugetlb.2MB.rsvd.current  memory.events.local  memory.reclaim        misc.events
cgroup.freeze           cpu.idle               cpu.stat               hugetlb.1GB.numa_stat     hugetlb.2MB.rsvd.max      memory.high          memory.stat           misc.max
cgroup.kill             cpu.max                cpu.uclamp.max         hugetlb.1GB.rsvd.current  io.max                    memory.low           memory.swap.current   pids.current
cgroup.max.depth        cpu.max.burst          cpu.uclamp.min         hugetlb.1GB.rsvd.max      io.pressure               memory.max           memory.swap.events    pids.events
cgroup.max.descendants  cpu.pressure           cpu.weight             hugetlb.2MB.current       io.prio.class             memory.min           memory.swap.high      pids.max
cgroup.procs            cpuset.cpus            cpu.weight.nice        hugetlb.2MB.events        io.stat                   memory.numa_stat     memory.swap.max       rdma.current
cgroup.stat             cpuset.cpus.effective  hugetlb.1GB.current    hugetlb.2MB.events.local  io.weight                 memory.oom.group     memory.zswap.current  rdma.max
cgroup.subtree_control  cpuset.cpus.partition  hugetlb.1GB.events     hugetlb.2MB.max           memory.current            memory.peak          memory.zswap.max
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep memory.li
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep limit

kill pid SIGTERM 15 default 可以被捕获 用于处理graceful-shutdown
kill -9 pid SIGKILL 9  不可以被捕获或者忽略  特权信号

内核决定给1号进程发送信号的时候，会调用sig_task_ignored来判断是否忽略
sig_task_ignored() 收到信号后会做一个判断，决定什么情况下内核会忽略掉信号不再处理,如果下面的三个条件都满足，这个信号就不会发送给进程
  值force 同一个namespace发出的信号值一直是0  !0 满足
  信号的handler是否是SIG_DFL,是就忽略，对于每个信号，如果用户进程不自己注册一个自己的handler,就会有一个系统缺省的handler,这个缺省的handler就是SIG_DFL  SIG_KILL满足（不允许被捕获，不允许自定义handler,handler是DFL），SIG_TERM如果没有自己注册handler,也是满足的
  SIGNAL_UNKILLABLE标签 flag ，只要是一号进程，就会有这个flag,满足
  关键是第二个条件，handler == DFL linux内核针对每个namespace里的init进程，把只有default handler的信号给忽略掉了

  所以init进程永远不能被SIGKILL杀死，可以被SIGTERM杀死 

  kill -9 1在容器中不工作，内核阻止了1号进程对sigkill特权信号的响应(信号的handler是 DFL)
  kill 1 分为两种情况，如果1号进程没有注册sigterm的handler,对sigterm信号不响应(C)，如果注册了sigterm的信号的handler,那么可以响应sigterm的信号（golang）
  
  1号进程是第一个用户态进程，由它直接或者间接创建了namespace中的其他进程

  linux 31个信号量 

  进程处理信号的三个情况：
  忽略 SIGKILL SIGSTOP除外
  捕获 进程注册自己的handler 捕获信号自己处理,而不会执行缺省代码
  缺省 

  进程或者线程 task_struct{}结构体

  linux机器允许创建的最大进程数目 
  /proc/sys/kernel/pid_max中

  限制容器中允许创建的最大进程数目  /sys/fs/cgroup/pids

 容器中允许被创建的最大进程数 
 [root@3ec18d539ddd cgroup]# cat /sys/fs/cgroup/pids.max 
2232

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# ls | grep pids.max 
pids.max
root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat pids.max 
2232
echo 1002 > pids.max

残留的僵尸进程依然占据着进程号资源，很有可能导致新的进程不能流转

如何处理僵尸进程？
僵尸进程产生的原因： 父进程创建之后就不再负责
解决： 父进程调用wait()系统调用，回收僵尸进程最后的资源，进程号

wait()是 阻塞的系统调用，没有子进程是僵尸进程的话，就会阻塞住
改用waitpid() 使用WHOHANG的参数，没有僵尸进程就会立即返回。
---------------------------------------------------------------
退出清理的操作，一般都是在SIGTERM信号用户注册的handler进行

containerd停止容器的时候，会向容器的init进程发出一个SIGTERM信号，而其他进程收到的是SIGKILL信号 （因为zap_pids_ns_processes()）

两个系统调用
kill() 发送信号
signal() 进程收到信号后的行为
    1.忽略  signal(SIGTERM,SIG_IGN)
    2.捕获，自定义处理handler signal(SIGTERM,sig_handler)   void sig_handler(int signo)
    3.缺省 signal(SIGTERM,SIG_DFL)  比如SIGTERM的缺省就是 terminate

SIGKILL 跟 SIGSTOP不能被捕获和忽略  signal(SIGKILL,sig_handler)会报错

linux内核处理进程退出：
do_exit() 回收进程相关资源
exit_notify() 通知进程相关的父子进程
zap_pid_ns_processes() 如果处于退出状态的是init进程，向同一个pid namespace的其他进程发送一个SIGKILL信号 

如何解决容器的应用程序被强制杀死？
在容器中的init进程中对收到的信号做个转发，发送给容器中的其他子进程，这样容器中的所有进程停止时，都会收到SIGTERM，而不是SIGKILL


--------------------------------CPU-------------------------------------
hi si 的CPU时间不会计入进程的CPU时间，因为他们本身处理的时候，不属于任何一个进程
ni nice(1-19) 进程优先级比较低的进程运行时候占用的cpu 

cgroup cpu /sys/fs/cgroup/cpu
每个控制组都是一个子目录，各个控制组的关系就是一个树状层级关系
普通调度的算法 CFS  completely fair scheduler 完全公平调度器
1.  cpu.cfs_period_us CFS调度算法的一个调度周期，一般是100ms   100 000   固定值
2.  cpu.cfs_quota_us 一个调度周期中这个控制组被允许的运行时间，比如50ms  50 000 
cpu.cfs_quota_us/cpu.cfs_period_us  = 该控制组被允许使用的cpu最大配额   50ms/100ms = 0.5 CPU 
3. cpu.shares cgroup对于控制组之间的CPU分配比例，默认是1024   group3 3072   group4 1024    group4:group3 = 3:1 

注意： cpu.shares是几个控制组之间的CPU分配比例，一定要等整个结点的cpu都跑满的之后才会发起作用

k8s cpu limits的原理
k8s 为每个容器都在 cpu cgroup的子系统中新建一个控制组，然后把容器的进程写到这个控制组中， 然后修改  cpu.cfs_quota_us设置limits 

k8s cpu requests的原理  (即 整个结点cpu被占满的情况下，容器可以获取的cpu数目)
通过设置 cpu.share参数，cpu.shares == 1024表示1个cpu的比例，request cpu的值是n, 给cpu.shares的赋值对应的是 n * 1024

cpu usage = us(或者ni) + sy 

--------------------------如何正确拿到容器CPU的开销-------------------------------
容器中运行top命令，实际看到的是容器宿主机的 cpu使用率, 原因是 /proc/stat 不包含在任一namespace中，它反应的是整个节点的cpu使用情况
对于top命令来说，它只能显示整个结点的CPU使用情况，不能显示单个容器的各项cpu的使用率

对于linux主机：
单个进程CPU使用率计算  /proc/[pid]/stat 计算用户态 跟 内核态的ticks数之和
系统CPU的使用率 /proc/stat 

如何计算整个容器的cpu使用率？
cpuacct.stat 包含了两个值，控制组内所有进程的内核态ticks 跟 用户态ticks

root@joedlut-virtual-machine:/sys/fs/cgroup/system.slice/docker-3ec18d539ddd09c53b35aa970330ff08c2da58f6ffc37f3624a58d0eabe88f76.scope# cat cpu.stat 
usage_usec 2900606
user_usec 1440885
system_usec 1459720
nr_periods 0
nr_throttled 0
throttled_usec 0
nr_bursts 0
burst_usec 0
---------------------------------------------------------------------------
load average =  单位时间内正在运行的进程 + 可运行队列的进程 + 休眠队列中不可打断（TASK_UNINTERRUPTIBLE）的进程     

TASK_UNINTERRUPTIBLE是linux进程状态中的一种，是进程为了等待某个系统资源进入了睡眠状态，并且这个状态是不可以被信号打断的  ps ux | grep " D "   造成D状态进程的原因  主要是disk I/O 跟信号量的访问竞争，目前cgroups 还不能解决 由于D状态的进程导致容器中进程性能下降的原因。 cgrups 更多的是影响以进程为单位进行隔离，而D状态的进程是内核中系统全局资源引入的，所以cgroups影响不了它。

需要监控生产环境中D状态的进程数量，然后对D状态的进程数目异常的节点进行分析，比如磁盘故障引起的D状态进程增加

-----------------------------容器内存--------------------------------------
容器在系统中被杀掉，只有一种情况 OOM， 容器发生OOM多是因为 memory cgroup 的限制导致的

使用docker inspect container_id  查看容器退出的原因

OOM根据如何选择被杀的进程
1.进程已经使用的物理内存页面数
2. 每个进程的 OOM 校准值   /proc/[pid]/oom_score_adj (-1000 - 1000),通过调整这个文件，可以调整进程被OOM杀死的几率

内核函数 oom_badness() 判断杀死哪个进程 的计算方法：
用系统总的可用页面数 乘以 OOM校准值 再加上  进程已经使用的物理页面数，计算的数值越大，被OOM杀死的几率越大 

k8s memory limits 原理， 调整 memory cgroup 参数  memory.limit_in_bytes 

如何快速定位容器发生了OOM?
查看内核日志  journalctl -k   或者查看/var/log/message

----------------------------------------------------------------------------------
memory group不会对内核的内存做限制

用户态内存
RSS
   进程真正申请到的物理内存大小  malloc只是把内存的虚拟地址返回给了进程，进程实际对内存读写的时候，系统才会分配内存。
   RSS = 进程的代码段内存 + 栈内存 + 堆内存 + 共享库内存   查看每一部分的内存大小： /proc/[pid]/smaps
Page Cache
   进程对磁盘文件进行读写，linux会分配内存，将磁盘读写的页面放到内存中; 作用： 提高磁盘文件的读写性能。

memory cgroup 只是统计了 RSS跟 page cache的内存之和
RSS + page cache = memory.usage_in_bytes

page cache 的内存在系统需要新申请物理内存的时候是可以被释放掉的， 是linux内核自发的行为，是要读写文件，只要有空闲的内存，就会用作page cache

判断容器的内存使用量，要用memory.stat的rss值，不能用memory.usage_in_bytes(含有page cache)

-----------------------------------------------------------------------------------------
/proc/sys/vm/swapiness 可以决定系统会有多频繁的使用交换分区 值越大，内核越频繁的使用交换分区。值越低，尽量避免使用交换分区。 默认值 60  取值范围 0-100 
100 即使有空闲内存，也还是会做内存交换
0 基本不做内存交换，不写swap空间

linux系统内存紧张时，先释放page cache 还是 先释放匿名内存(malloc)， 通过swapiness来平衡，swapiness更像是一个权重，用来定义page cache内存 和 匿名内存释放的一个比例
anon_prio : file_prio   =   swapiness : 200 - swapiness = 匿名内存 : page cache 

cat /proc/zoneinfo free < high （water mark）系统会回收匿名内存页面到swap空间  即使swapiness = 0 

memory cgroup 参数   memory.swappiness 控制 控制组下匿名内存 和 page cache的回收，memory swapiness会覆盖全局的swappiness， 与全局的swappiness有一点不同：memory.swappiness = 0 ，对于匿名内存的回收是始终禁止的，始终不会使用swap空间 

将memory.swappiness = 0 可以让使用swap空间的容器 跟 不需要swap（对应容器的控制组的 memory.swappiness 设置为0 ）的容器一台宿主机上，互不影响

----------------------容器的文件系统--------------------------------------------
overlay 
有效减少冗余的镜像数据在网路上的传输，减少磁盘上冗余的镜像数据，针对容器的文件系统 UnionFS

UnionFS 主要功能是将多个目录一起挂在到同一个目录下。

UnionFS的实现  
    OverlayFS  mount两层目录  lowerdir （只读）    upperdir（可读写） |  merged 挂载点目录（mount point) 用户看到的目录，用户的实际文件操作都在这里进行

容器的镜像文件中各层为 overlayFS的lowerdir层 再加一个空的upperdir层 一起挂在好后，组成了容器的文件系统

-----------------------------------------------------------------------------
overlayFS  upperdir lowerdir
往upperdir写数据实际写入的是宿主机的磁盘
     
XFS ext4  Quota 特性 限制一个用户，一个用户组或者一个project来限制他们使用文件系统的维度

如何限制容器不会写满宿主机的磁盘？
针对 overlayFS的upperdir做 XFS quota的限流

---------------------------------------------------------
限制容器io 的读写性能
blkio cgroup 
磁盘的性能指标：
IOPS   每秒磁盘中数据的读写的次数
Throughout  吞吐量 每秒磁盘中数据的读取量  MB/s

IOPS固定的情况下  吞吐量 = 数据块大小 * IOPS

/sys/fs/cgroup/blkio 创建子目录作为控制组 

direct I/O  bufferd IO

Cgroup V1 blkio控制子系统 只能对Direct IO的读写文件做磁盘限速，对于Buffered IO的文件读写，它无法进行磁盘限速； 因为buffered IO会把数据先写入到内存page cache中，内核线程把数据写入磁盘，而Cgroup V1 blkio的子系统独立于memory子系统，无法统计到由page cache刷入到磁盘的数据量
Cgroup V2从架构上允许一个控制组里多个子系统协同运行，针对buffered IO进行磁盘读写的限速
---------------------------------------------------------------
容器做内存限制的时候，cgroup 中memory.limit_in_bytes设置的比较小，容器中进程有很多大量io,这样申请新的page cache内存时会不断释放老的内存页面，这些操作会带来额外的系统开销。

容器中使用buffered IO方式写文件的时候，会出现写入时间的波动，这是由于文件会先写到内存里，这样就产生了大量的dirty pages

有时间做一下这个实验

perf  fstrace工具 分析容器中写文件进程的profile. perf得到系统调用write()在内核中的一系列子函数调用，再用ftrace查看这些子函数的调用时间
跟句fstrace的结果，写数据到page cache的时候，需要不断去释放原有的页面，这个时间开销是最大的。 造成容器中的buffered IO不稳定的原因，正是容器在限制内存之后，page cache的数量较小并且不断申请释放。

针对容器做memory cgroup限制的时候，不仅要考虑进程实际使用的内存量，还要考虑容器中程序IO的量，合理预留足够的内存作为buffered IO的page cache
如果知道读写文件的大小，并且知道内存足够的情况下，memory cgroup的限制可以超过这个文件的大小。| 或者程序管理自己的cache 并且调用direct IO来读写文件

当dirty_pages 超过dirty_backgroup_ratio对应的内存量，内核flush线程会把dirty_pages写入磁盘；
当dirty_pages 超过dirty_ratio对应的内存量，程序写文件的函数调用write()会阻塞住，直到这次调用的dirty_pages全部写入到磁盘中。 
-------------------------------容器网络隔离---------------------------------
network namespace隔离了哪些资源？
1.网络设备 
2.ipv4  ipv6协议栈
3.ip 路由表
4. iptables规则
5. 网络状态信息  /proc/net  

如何建立一个新的network namespace
通过clone() 或者 unshare建立新的network namespace 

clone() 系统调用加上 CLONE_NEWNET flag实现  新的进程，新的network namespace 

unshare() 直接改变当前进程的network namespace

或者使用命令行创建  ip netns 

lsns -t net 查看系统已有的network namespace 

使用nsenter 查看某个net namespace的网络配置


root@joedlut-virtual-machine:~# lsns -t net
        NS TYPE NPROCS   PID USER       NETNSID NSFS                           COMMAND
4026531840 net     361     1 root    unassigned                                /sbin/init splash
4026532640 net       1   797 root    unassigned                                ├─/usr/libexec/accounts-daemon
4026532770 net       1  1014 rtkit   unassigned                                └─/usr/libexec/rtkit-daemon
4026532711 net       8  5843 root             0 /run/docker/netns/ac5eb25d8a1c /bin/sh /usr/sbin/apachectl -DFOREGROUND
4026532851 net       2 14455 joedlut unassigned                                /usr/bin/bwrap --args 33 -- /usr/lib/x86_64-linux-gnu/webkit2gtk-4.1/WebKitWebProcess 11 28
root@joedlut-virtual-machine:~# nsenter -t 5843 -n ip addr 
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
4: eth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default 
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever


如何修改容器中的network namespace的网络参数？
普通容器的/proc/sys 是readonly mount的，容器启动以后，我们无法再容器内部修改 /proc/sys/net下网络相关的参数

1. 宿主机如果有root权限，使用nsenter 工具修改，不被允许
2.修改network namespace  的时机，选在容器刚启动，而容器中的应用程序还没有启动之前进行

可以通过docker的 --sysctl 或者 k8s allowed-unsafe-sysctls特性 在容器启动时修改容器 namespace的参数 






